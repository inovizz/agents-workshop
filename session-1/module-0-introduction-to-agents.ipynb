{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2e0d5a",
   "metadata": {},
   "source": [
    "## Why AI Agents?\n",
    "\n",
    "### What's So Exciting About Agents?\n",
    "\n",
    "Imagine an AI that doesn't just answer questions, but actually **does things** for you:\n",
    "\n",
    "- ðŸ“§ **Reads your emails** and drafts responses\n",
    "- ðŸ“Š **Analyzes data** and creates reports\n",
    "- ðŸ›’ **Books flights**, hotels, and restaurants\n",
    "- ðŸ’» **Writes, tests, and deploys code**\n",
    "- ðŸ” **Researches topics** across multiple sources\n",
    "\n",
    "This isn't science fictionâ€”**this is what AI agents can do today**.\n",
    "\n",
    "### The Evolution: From Chat to Action\n",
    "\n",
    "```\n",
    "Traditional LLM          â†’          AI Agent\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\"What's the weather?\"               \"What's the weather?\"\n",
    "      â†“                                   â†“\n",
    "\"I don't have real-time              Calls weather API\n",
    " access to weather data\"                  â†“\n",
    "                                    \"It's 22Â°C and sunny\n",
    "                                     in New York!\"\n",
    "```\n",
    "\n",
    "The key difference: **Agents can take actions in the real world**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09176bf1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What Exactly Is an AI Agent?\n",
    "\n",
    "### The Simple Definition\n",
    "\n",
    "> **An AI Agent is a system that uses an LLM to decide which actions to take and in what order.**\n",
    "\n",
    "Unlike traditional software with fixed logic, agents use the LLM's reasoning to determine:\n",
    "- **What** actions to take\n",
    "- **When** to take them\n",
    "- **How** to adapt based on results\n",
    "\n",
    "### The Three Core Components\n",
    "\n",
    "Every AI agent has three essential building blocks:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                       AI AGENT                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚   ðŸ§  MODEL (Brain)                                      â”‚\n",
    "â”‚   â””â”€â”€ LLM that reasons and makes decisions              â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚   ðŸ› ï¸ TOOLS (Hands)                                      â”‚\n",
    "â”‚   â””â”€â”€ Functions the agent can call                      â”‚\n",
    "â”‚       (APIs, databases, calculations, etc.)             â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚   ðŸ“‹ INSTRUCTIONS (Personality)                         â”‚\n",
    "â”‚   â””â”€â”€ System prompt defining behaviour and goals        â”‚\n",
    "â”‚                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### What Makes Agents Powerful?\n",
    "\n",
    "The magic happens when these components work together in a **loop**:\n",
    "\n",
    "```\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”‚                  â”‚\n",
    "        â–¼                  â”‚\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚\n",
    "   â”‚ Observe â”‚ â—„â”€â”€ User input / Environment\n",
    "   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â”‚\n",
    "        â”‚                  â”‚\n",
    "        â–¼                  â”‚\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚\n",
    "   â”‚  Think  â”‚ â—„â”€â”€ LLM reasons about situation\n",
    "   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â”‚\n",
    "        â”‚                  â”‚\n",
    "        â–¼                  â”‚\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚\n",
    "   â”‚   Act   â”‚ â—„â”€â”€ Call tools, execute actions\n",
    "   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â”‚\n",
    "        â”‚                  â”‚\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           (Loop continues)\n",
    "```\n",
    "\n",
    "This **observe-think-act loop** continues until the agent completes its goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab04b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Workflows vs. Agents\n",
    "\n",
    "Understanding the difference between workflows and agents is crucial:\n",
    "\n",
    "### Workflows: Predictable Orchestration\n",
    "\n",
    "**Workflows** are systems where LLMs and tools are orchestrated through **predefined code paths**.\n",
    "\n",
    "```\n",
    "WORKFLOW EXAMPLE: Document Processing Pipeline\n",
    "\n",
    "     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "     â”‚ Extract â”‚ â”€â”€â–º â”‚ Classifyâ”‚ â”€â”€â–º â”‚Summarizeâ”‚\n",
    "     â”‚  Text   â”‚     â”‚Document â”‚     â”‚ Content â”‚\n",
    "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â–²\n",
    "         â”‚\n",
    "     Input PDF\n",
    "\n",
    "âœ“ Fixed sequence\n",
    "âœ“ Predictable steps\n",
    "âœ“ Easy to debug\n",
    "```\n",
    "\n",
    "### Agents: Autonomous Decision-Making\n",
    "\n",
    "**Agents** are systems where the LLM **dynamically decides** what to do next.\n",
    "\n",
    "```\n",
    "AGENT EXAMPLE: Research Assistant\n",
    "\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚   LLM   â”‚\n",
    "                    â”‚ Decides â”‚\n",
    "                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
    "                         â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â–¼               â–¼               â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ Search  â”‚    â”‚  Read   â”‚    â”‚  Write  â”‚\n",
    "    â”‚   Web   â”‚    â”‚  File   â”‚    â”‚ Summary â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "âœ“ Dynamic decisions\n",
    "âœ“ Adapts to context\n",
    "âœ“ Autonomous looping\n",
    "```\n",
    "\n",
    "\n",
    "### Agentic Workflows: Structured Autonomy\n",
    "\n",
    "**Agentic workflows** combine predefined structure with LLM decision-making. You define possible paths, the LLM chooses which one.\n",
    "\n",
    "```\n",
    "AGENTIC WORKFLOW EXAMPLE: Customer Support Router\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚   LLM   â”‚\n",
    "                    â”‚ Routes  â”‚\n",
    "                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
    "                         â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â–¼               â–¼               â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚   FAQ   â”‚    â”‚ Refund  â”‚    â”‚Escalate â”‚\n",
    "    â”‚ Lookup  â”‚    â”‚  Flow   â”‚    â”‚ to Humanâ”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "âœ“ LLM chooses path\n",
    "âœ“ Bounded options\n",
    "âœ“ Predictable + flexible\n",
    "The sweet spot for production: More flexible than rigid workflows, more controllable than pure agents.\n",
    "```\n",
    "\n",
    "### Quick Comparison\n",
    "\n",
    "| Aspect | Workflow | Agentic Workflow | Agent |\n",
    "|--------|----------|------------------|-------|\n",
    "| **Control Flow** | Code determines path | LLM chooses from defined paths | LLM determines path |\n",
    "| **Predictability** | High (fixed steps) | Medium (known options) | Lower (dynamic) |\n",
    "| **Flexibility** | Limited to defined paths | Adapts within structure | Adapts to new situations |\n",
    "| **Debugging** | Easier (trace code) | Moderate (trace decisions) | Harder (trace reasoning) |\n",
    "| **Best For** | Repetitive tasks | Tasks with multiple valid approaches | Complex, varied tasks |\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "**Use Workflows when:**\n",
    "- The task has clear, predictable steps\n",
    "- You need maximum reliability and auditability\n",
    "- The problem is well-defined\n",
    "\n",
    "**Use Agents when:**\n",
    "- Tasks require dynamic decision-making\n",
    "- You need adaptability to varied inputs\n",
    "- The problem may need multiple approaches\n",
    "\n",
    "**Use Agentic Workflows when:**\n",
    "\n",
    "- Multiple valid approaches exist for the same task\n",
    "- You want LLM intelligence but need guardrails\n",
    "- You need balance between flexibility and control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3759cb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "Let's set up our environment to build agents with **LangGraph** and **LangChain**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "610531b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ LLM Setup Utility Test\n",
      "\n",
      "ðŸ” Checking LLM Configuration...\n",
      "==================================================\n",
      "ðŸ“¡ Provider: DIAL (Azure OpenAI via EPAM AI Proxy)\n",
      "âœ… DIAL_API_KEY is set\n",
      "\n",
      "ðŸ“‹ Configuration:\n",
      "   AZURE_OPENAI_ENDPOINT: https://ai-proxy.lab.epam.com\n",
      "   AZURE_OPENAI_API_VERSION: 2024-02-01\n",
      "   AZURE_OPENAI_DEPLOYMENT_NAME: gpt-4\n",
      "\n",
      "âœ… DIAL setup verified successfully!\n",
      "\n",
      "ðŸ“ Testing model initialization...\n",
      "âœ… Model created: gpt-4 via DIAL (Azure OpenAI)\n",
      "âœ… Test response: Hello!\n",
      "âœ… Test response: Hello!\n"
     ]
    }
   ],
   "source": [
    "# Run our setup script to configure DIAL (EPAM AI Proxy)\n",
    "%run ../setup_llm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cba1222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ”§ Agentic AI Workshop - LLM Setup Verification\n",
      "============================================================\n",
      "\n",
      "ðŸ” Checking LLM Configuration...\n",
      "==================================================\n",
      "ðŸ“¡ Provider: DIAL (Azure OpenAI via EPAM AI Proxy)\n",
      "âœ… DIAL_API_KEY is set\n",
      "\n",
      "ðŸ“‹ Configuration:\n",
      "   AZURE_OPENAI_ENDPOINT: https://ai-proxy.lab.epam.com\n",
      "   AZURE_OPENAI_API_VERSION: 2024-02-01\n",
      "   AZURE_OPENAI_DEPLOYMENT_NAME: gpt-4\n",
      "\n",
      "âœ… DIAL setup verified successfully!\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª Testing LLM Connection...\n",
      "============================================================\n",
      "\n",
      "ðŸ“¡ Connecting via DIAL (Azure OpenAI) with model: gpt-4\n",
      "\n",
      "âœ… Response: Connection successful!\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ SUCCESS! Your LLM setup is working correctly!\n",
      "============================================================\n",
      "\n",
      "You can now run the workshop notebooks.\n",
      "\n",
      "âœ… Response: Connection successful!\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ SUCCESS! Your LLM setup is working correctly!\n",
      "============================================================\n",
      "\n",
      "You can now run the workshop notebooks.\n"
     ]
    }
   ],
   "source": [
    "# Verify our environment is working\n",
    "%run ../verify_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7e24767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment ready!\n",
      "   Model: gpt-4 (via DIAL)\n"
     ]
    }
   ],
   "source": [
    "# Import the core libraries we'll use throughout\n",
    "from setup_llm import get_chat_model  # Use LLM helper\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize our LLM model using DIAL (Azure OpenAI)\n",
    "# Default deployment is 'gpt-4' from environment\n",
    "model = get_chat_model(temperature=0)\n",
    "\n",
    "print(\"âœ… Environment ready!\")\n",
    "print(f\"   Model: gpt-4 (via DIAL)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71d5fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Build Your First Agent ðŸŽ‰\n",
    "\n",
    "Let's build a simple agent with one tool. This demonstrates the core concept: **an LLM that can call functions**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409ac1b",
   "metadata": {},
   "source": [
    "### Step 1: Define a Tool\n",
    "\n",
    "Tools are functions that extend what the LLM can do. We use the `@tool` decorator to make any Python function available to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f807501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: get_current_time\n",
      "Tool description: Get the current date and time.\n",
      "\n",
      "Returns:\n",
      "    A string with the current date and time in a readable format.\n",
      "\n",
      "Direct call result: Wednesday, December 03, 2025 at 05:29 PM\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    Get the current date and time.\n",
    "    \n",
    "    Returns:\n",
    "        A string with the current date and time in a readable format.\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%A, %B %d, %Y at %I:%M %p\")\n",
    "\n",
    "# Test the tool directly\n",
    "print(\"Tool name:\", get_current_time.name)\n",
    "print(\"Tool description:\", get_current_time.description)\n",
    "print(\"\\nDirect call result:\", get_current_time.invoke({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c4bae",
   "metadata": {},
   "source": [
    "### Step 2: Create the Agent\n",
    "\n",
    "Now we combine the **model** (brain) + **tools** (hands) to create an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e733fca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created!\n",
      "   Model: gpt-4 (via DIAL)\n",
      "   Tools: get_current_time\n"
     ]
    }
   ],
   "source": [
    "# Create our first agent using create_agent (LangChain v1.0)\n",
    "my_first_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_current_time]\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created!\")\n",
    "print(\"   Model: gpt-4 (via DIAL)\")\n",
    "print(\"   Tools: get_current_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e692d",
   "metadata": {},
   "source": [
    "### Step 3: Test the Agent\n",
    "\n",
    "Let's see our agent in action! Watch how it **decides** to use the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03226ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What time is it right now?', additional_kwargs={}, response_metadata={}, id='eef72ea5-ee5b-460a-a6e6-26bbfde1864d'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 61, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CifoT6qXh3kkDFTVXFs13dTAaipgj', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='lc_run--159bc710-50f9-4b25-b32c-2a6099f48b19-0', tool_calls=[{'name': 'get_current_time', 'args': {}, 'id': 'call_ZoezXQ7jPh1rnjA8ZOoJn4sp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 12, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Wednesday, December 03, 2025 at 05:29 PM', name='get_current_time', id='b2f398fa-e298-41d9-98c4-b2f26ec26c5e', tool_call_id='call_ZoezXQ7jPh1rnjA8ZOoJn4sp'), AIMessage(content='It is currently Wednesday, December 3, 2025, at 5:29 PM.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 96, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CifoUds9FXtIZUYeC9s9CGaZkyNr3', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='lc_run--30c92ba8-819b-4806-a4cb-c44dd9e36cb4-0', usage_metadata={'input_tokens': 96, 'output_tokens': 22, 'total_tokens': 118, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "# Ask something that requires the tool\n",
    "response = my_first_agent.invoke({\n",
    "    \"messages\": [(\"user\", \"What time is it right now?\")]\n",
    "})\n",
    "print(response)\n",
    "# Print the agent's response\n",
    "# print(\"ðŸ¤– Agent Response:\")\n",
    "# print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a394d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Full Conversation Trace:\n",
      "==================================================\n",
      "\n",
      "1. [HUMAN] What time is it right now?\n",
      "\n",
      "2. [AI] ðŸ”§ Tool Call:\n",
      "      â†’ get_current_time({})\n",
      "\n",
      "3. [TOOL] Wednesday, December 03, 2025 at 05:29 PM\n",
      "\n",
      "4. [AI] It is currently Wednesday, December 3, 2025, at 5:29 PM.\n",
      "\n",
      "==================================================\n",
      "âœ… The agent decided to call get_current_time!\n"
     ]
    }
   ],
   "source": [
    "# Let's trace what happened behind the scenes\n",
    "print(\"ðŸ“ Full Conversation Trace:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, msg in enumerate(response[\"messages\"], 1):\n",
    "    role = msg.type.upper()\n",
    "    \n",
    "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        print(f\"\\n{i}. [{role}] ðŸ”§ Tool Call:\")\n",
    "        for call in msg.tool_calls:\n",
    "            print(f\"      â†’ {call['name']}({call['args']})\")\n",
    "    elif hasattr(msg, 'content') and msg.content:\n",
    "        content = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "        print(f\"\\n{i}. [{role}] {content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"âœ… The agent decided to call get_current_time!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e012ccd9",
   "metadata": {},
   "source": [
    "### Step 4: Test Agent Decision-Making\n",
    "\n",
    "The agent only uses tools **when needed**. Let's verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26012047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Question: What is 2 + 2?\n",
      "   Response: 2 + 2 equals 4.\n",
      "\n",
      "   Tool called: No\n",
      "   âœ… Smart! The agent knew it didn't need the time tool for math.\n"
     ]
    }
   ],
   "source": [
    "# Ask something that doesn't need the tool\n",
    "response_no_tool = my_first_agent.invoke({\n",
    "    \"messages\": [(\"user\", \"What is 2 + 2?\")]\n",
    "})\n",
    "\n",
    "print(\"ðŸ¤– Question: What is 2 + 2?\")\n",
    "print(f\"   Response: {response_no_tool['messages'][-1].content}\")\n",
    "\n",
    "# Check if any tools were called\n",
    "tool_used = any(\n",
    "    hasattr(msg, 'tool_calls') and msg.tool_calls \n",
    "    for msg in response_no_tool['messages']\n",
    ")\n",
    "\n",
    "print(f\"\\n   Tool called: {'Yes' if tool_used else 'No'}\")\n",
    "print(\"   âœ… Smart! The agent knew it didn't need the time tool for math.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e727cc8-13b2-4600-8a4d-349fb2db5189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "create_agent(\n",
      "    model: \u001b[33m'str | BaseChatModel'\u001b[39m,\n",
      "    tools: \u001b[33m'Sequence[BaseTool | Callable | dict[str, Any]] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    *,\n",
      "    system_prompt: \u001b[33m'str | SystemMessage | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    middleware: \u001b[33m'Sequence[AgentMiddleware[StateT_co, ContextT]]'\u001b[39m = (),\n",
      "    response_format: \u001b[33m'ResponseFormat[ResponseT] | type[ResponseT] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    state_schema: \u001b[33m'type[AgentState[ResponseT]] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    context_schema: \u001b[33m'type[ContextT] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    checkpointer: \u001b[33m'Checkpointer | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    store: \u001b[33m'BaseStore | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    interrupt_before: \u001b[33m'list[str] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    interrupt_after: \u001b[33m'list[str] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    debug: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    name: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    cache: \u001b[33m'BaseCache | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ") -> \u001b[33m'CompiledStateGraph[AgentState[ResponseT], ContextT, _InputAgentState, _OutputAgentState[ResponseT]]'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Creates an agent graph that calls tools in a loop until a stopping condition is met.\n",
      "\n",
      "For more details on using `create_agent`,\n",
      "visit the [Agents](https://docs.langchain.com/oss/python/langchain/agents) docs.\n",
      "\n",
      "Args:\n",
      "    model: The language model for the agent.\n",
      "\n",
      "        Can be a string identifier (e.g., `\"openai:gpt-4\"`) or a direct chat model\n",
      "        instance (e.g., [`ChatOpenAI`][langchain_openai.ChatOpenAI] or other another\n",
      "        [LangChain chat model](https://docs.langchain.com/oss/python/integrations/chat)).\n",
      "\n",
      "        For a full list of supported model strings, see\n",
      "        [`init_chat_model`][langchain.chat_models.init_chat_model(model_provider)].\n",
      "\n",
      "        !!! tip \"\"\n",
      "\n",
      "            See the [Models](https://docs.langchain.com/oss/python/langchain/models)\n",
      "            docs for more information.\n",
      "    tools: A list of tools, `dict`, or `Callable`.\n",
      "\n",
      "        If `None` or an empty list, the agent will consist of a model node without a\n",
      "        tool calling loop.\n",
      "\n",
      "\n",
      "        !!! tip \"\"\n",
      "\n",
      "            See the [Tools](https://docs.langchain.com/oss/python/langchain/tools)\n",
      "            docs for more information.\n",
      "    system_prompt: An optional system prompt for the LLM.\n",
      "\n",
      "        Can be a `str` (which will be converted to a `SystemMessage`) or a\n",
      "        `SystemMessage` instance directly. The system message is added to the\n",
      "        beginning of the message list when calling the model.\n",
      "    middleware: A sequence of middleware instances to apply to the agent.\n",
      "\n",
      "        Middleware can intercept and modify agent behavior at various stages.\n",
      "\n",
      "        !!! tip \"\"\n",
      "\n",
      "            See the [Middleware](https://docs.langchain.com/oss/python/langchain/middleware)\n",
      "            docs for more information.\n",
      "    response_format: An optional configuration for structured responses.\n",
      "\n",
      "        Can be a `ToolStrategy`, `ProviderStrategy`, or a Pydantic model class.\n",
      "\n",
      "        If provided, the agent will handle structured output during the\n",
      "        conversation flow.\n",
      "\n",
      "        Raw schemas will be wrapped in an appropriate strategy based on model\n",
      "        capabilities.\n",
      "\n",
      "        !!! tip \"\"\n",
      "\n",
      "            See the [Structured output](https://docs.langchain.com/oss/python/langchain/structured-output)\n",
      "            docs for more information.\n",
      "    state_schema: An optional `TypedDict` schema that extends `AgentState`.\n",
      "\n",
      "        When provided, this schema is used instead of `AgentState` as the base\n",
      "        schema for merging with middleware state schemas. This allows users to\n",
      "        add custom state fields without needing to create custom middleware.\n",
      "\n",
      "        Generally, it's recommended to use `state_schema` extensions via middleware\n",
      "        to keep relevant extensions scoped to corresponding hooks / tools.\n",
      "    context_schema: An optional schema for runtime context.\n",
      "    checkpointer: An optional checkpoint saver object.\n",
      "\n",
      "        Used for persisting the state of the graph (e.g., as chat memory) for a\n",
      "        single thread (e.g., a single conversation).\n",
      "    store: An optional store object.\n",
      "\n",
      "        Used for persisting data across multiple threads (e.g., multiple\n",
      "        conversations / users).\n",
      "    interrupt_before: An optional list of node names to interrupt before.\n",
      "\n",
      "        Useful if you want to add a user confirmation or other interrupt\n",
      "        before taking an action.\n",
      "    interrupt_after: An optional list of node names to interrupt after.\n",
      "\n",
      "        Useful if you want to return directly or run additional processing\n",
      "        on an output.\n",
      "    debug: Whether to enable verbose logging for graph execution.\n",
      "\n",
      "        When enabled, prints detailed information about each node execution, state\n",
      "        updates, and transitions during agent runtime. Useful for debugging\n",
      "        middleware behavior and understanding agent execution flow.\n",
      "    name: An optional name for the `CompiledStateGraph`.\n",
      "\n",
      "        This name will be automatically used when adding the agent graph to\n",
      "        another graph as a subgraph node - particularly useful for building\n",
      "        multi-agent systems.\n",
      "    cache: An optional `BaseCache` instance to enable caching of graph execution.\n",
      "\n",
      "Returns:\n",
      "    A compiled `StateGraph` that can be used for chat interactions.\n",
      "\n",
      "The agent node calls the language model with the messages list (after applying\n",
      "the system prompt). If the resulting [`AIMessage`][langchain.messages.AIMessage]\n",
      "contains `tool_calls`, the graph will then call the tools. The tools node executes\n",
      "the tools and adds the responses to the messages list as\n",
      "[`ToolMessage`][langchain.messages.ToolMessage] objects. The agent node then calls\n",
      "the language model again. The process repeats until no more `tool_calls` are present\n",
      "in the response. The agent then returns the full list of messages.\n",
      "\n",
      "Example:\n",
      "    ```python\n",
      "    from langchain.agents import create_agent\n",
      "\n",
      "\n",
      "    def check_weather(location: str) -> str:\n",
      "        '''Return the weather forecast for the specified location.'''\n",
      "        return f\"It's always sunny in {location}\"\n",
      "\n",
      "\n",
      "    graph = create_agent(\n",
      "        model=\"anthropic:claude-sonnet-4-5-20250929\",\n",
      "        tools=[check_weather],\n",
      "        system_prompt=\"You are a helpful assistant\",\n",
      "    )\n",
      "    inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
      "    for chunk in graph.stream(inputs, stream_mode=\"updates\"):\n",
      "        print(chunk)\n",
      "    ```\n",
      "\u001b[31mFile:\u001b[39m      ~/Workspace/python-ws/Agentic-AI Workshops/.venv/lib/python3.13/site-packages/langchain/agents/factory.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "create_agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38a451",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Why Agents Matter**: They transform AI from answering questions to taking actions\n",
    "\n",
    "2. **Agent Definition**: A system where an LLM decides which actions to take and when\n",
    "\n",
    "3. **Three Core Components**:\n",
    "   - ðŸ§  **Model** (Brain) - The LLM that reasons\n",
    "   - ðŸ› ï¸ **Tools** (Hands) - Functions the agent can call\n",
    "   - ðŸ“‹ **Instructions** (Personality) - System prompts and goals\n",
    "\n",
    "4. **Workflows vs. Agents vs Agentic Workflows**:\n",
    "   - Workflows: Fixed code paths, predictable\n",
    "   - Agents: Dynamic LLM decisions, adaptive\n",
    "\n",
    "5. **Building Agents**: \n",
    "   - Define tools with `@tool` decorator\n",
    "   - Create agent with `create_agent(model, tools)`\n",
    "   - Agent autonomously decides when to use tools\n",
    "\n",
    "### What's Next\n",
    "\n",
    "In **Module 1**, we'll dive deeper into:\n",
    "- The **ReAct framework** that powers our agents\n",
    "- **State management** with LangGraph\n",
    "- Building more complex agent workflows\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Exercise\n",
    "\n",
    "**Challenge**: Add a second tool and create a more capable agent!\n",
    "\n",
    "1. Create a `get_weather(city: str)` tool (simulated data is fine)\n",
    "2. Create an agent with both tools\n",
    "3. Test with: \"What's the weather in Paris and what time is it there?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a85c007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Implement your solution above!\n"
     ]
    }
   ],
   "source": [
    "# Your solution here:\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a city.\n",
    "    \n",
    "    Args:\n",
    "        city: The name of the city to check weather for\n",
    "        \n",
    "    Returns:\n",
    "        Current weather conditions for the city\n",
    "    \"\"\"\n",
    "    # Simulated weather data\n",
    "    weather_data = {\n",
    "        \"paris\": \"22Â°C, sunny with light clouds\",\n",
    "        \"london\": \"15Â°C, rainy\",\n",
    "        \"tokyo\": \"28Â°C, humid and partly cloudy\",\n",
    "        \"new york\": \"18Â°C, clear skies\",\n",
    "        \"sydney\": \"20Â°C, breezy and pleasant\"\n",
    "    }\n",
    "    return weather_data.get(city.lower(), f\"Weather data not available for {city}\")\n",
    "\n",
    "# TODO: Create an agent with both tools\n",
    "# multi_tool_agent = create_agent(...)\n",
    "\n",
    "# TODO: Test with the challenge question\n",
    "# response = multi_tool_agent.invoke(...)\n",
    "\n",
    "print(\"ðŸ’¡ Implement your solution above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4212b-4cc6-4372-98cf-f77ddfcf753a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
